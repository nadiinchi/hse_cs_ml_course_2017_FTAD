{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание, семинар 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании вы экспериментально выясните, почему глубокие деревья хорошо подходят для построения случайного леса. \n",
    "\n",
    "Мы будем пользоваться следующей методикой. Мы хотим установить, что семейство алгоритмов А обладает свойством Б. Мы находим в теории фрагмент, где описаны достаточные условия для выполнения условия Б, и проверяем, что А им удовлетворяет. \n",
    "\n",
    "Конкретно у нас: А - глубокие деревья, Б - эффективный бутстрап, он же бэггинг (эффективный - то есть показывающий хорошее качество), достаточное условие - некоррелированность ошибок базовых алгоритмов. Рассмотрим подробнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Фрагмент теории про построение эффективных композиций.__\n",
    "\n",
    "В [лекции 8](https://github.com/esokolov/ml-course-hse/blob/master/2017-fall/lecture-notes/lecture08-ensembles.pdf) в разделе про бутстрап было показано, что если у нас есть $N$ алгоритмов $b_1(x) \\dots b_N(x)$, ошибки которых несмещены:\n",
    "$$\\mathbb{E}_x[b_j(x) - y(x)] = 0$$\n",
    "и некоррелированы:\n",
    "$$\\mathbb{E}_x (b_i(x) - y(x))(b_j(x) - y(x)) = 0, i \\ne j,$$\n",
    "то матожидание ошибки композиции $b(x) = \\sum_j b_j(x)$ в $N$ раз меньше, чем одного отдельного алгоритма. Перечитайте этот фрагмент лекции, если не очень понятно, о чем речь.\n",
    "\n",
    "Несмещенность ошибок означает, что алгоритм с одинковой вероятностью ошибается в большую и меньшую сторону. Это условие обычно выполняется для всех алгоритмов (если мы только специально не задаем вес ошибок в какую-то из сторон больше при обучении). \n",
    "\n",
    "Коррелированность ошибок подразумевает, что если один алгоритм сильно ошибся на каком-то объекте, то и другой тоже сильно ошибется. Для построения эффективной композиции надо, чтобы это не выполнялось.\n",
    "\n",
    "Попробуем разобраться, какие алгоритмы будут коррелированными, а какие - по крайней мере не сильно коррелированы.\n",
    "\n",
    "Самый простой алгоритм - константа $b(x) = C$. Ясно, что несмещенный такой алгоритм можно построить только один: $C = \\mathbb{E}_x y(x)$. С таким простым алгоритмом каши не сваришь.\n",
    "\n",
    "Далее по простоте, наверно, идут решающие пни - деревья глубины один. Это почти константа, только в двух разных областях пространства ответов своя. Как вы думаете, будут ли коррелированы два решающих пня, обученных по разным подвыборкам? \n",
    "\n",
    "А если брать глубокие деревья?\n",
    "\n",
    "Вроде бы пни - соссем несложная вещь, и интегралы с ними легко считаются (если выбрать какое-то распределениями над объектами и целевую зависимость), но понять, равен ли интеграл нулю, как-то быстро не получается. Зато можно проверить численно, чем мы и займемся.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Постановка эксперимента.__\n",
    "\n",
    "Итак, нам надо проверить, будут ли коррелировать ошибки деревьев, обученных по разным подвыборкам. И проверить это для деревьев разной глубины.\n",
    "\n",
    "Возьмем датасет Бостон (регрессия стоимости жилья). Разделим на две части - по одной будем обучать алгоритмы, по другой - проверять ошибки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_boston()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# перемешайте датасет, возьмите первую половину объектов в обучение, вторую - в \"контроль\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала реализуем процедуру бэггинга. Надо с помощью np.random.randint сгенерировать индексы объектов обучающей выборки (получится с повторениями, нам так и надо), выбрать соответствующие объекты и обучить на них дерево. Будем везде считать, что длина бустрапированной выборки совпадает с длиной исходной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# обучите 2 одинаковых дерева (например, с настройками по умолчанию) по разным бутстрапированным выборкам\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь научимся оценивать смещенность и коррелированность.\n",
    "\n",
    "__Теоретическая справка: приближенное вычисление интегралов__\n",
    "\n",
    "Если нам нужно оценить математическое ожидание $\\mathbb{E}_{x \\sim p(x)} f(x) = \\int f(x) p(x) dx$, то можно просемплировать выборку $\\{x_1, \\dots, x_n\\}$ из распределения $p(x)$  и приближенно вычислить ннтеграл:\n",
    "    $$\n",
    "    \\mathbb{E}_{x \\sim p(x)} f(x) \\approx \\frac 1 n \\sum_{i=1}^n f(x_i).\n",
    "    $$\n",
    "    Из областей с большим значением плотности в выборку попадет больше точек, и они внесут больший вклад в значение интеграла.\n",
    "    \n",
    "В нашем случае математическое ожидание берется по распределению над объектами $p(x)$. Ясно, что в жизни мы это распределение не знаем, однако выборка из этого распределения у нас есть, а именно она и нужна для приближенного оценивания.\n",
    "\n",
    "Итак, надо посмотреть, какая функция стоит под мат. ожиданием, вычислить ее для всех точек из \"контрольной\" выборки и усреднить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оцените смещенность каждого из двух обученных деревьев, используя вторую (\"контрольную\") выборку\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оцените кореллированность двух деревьев, используя вторую (\"контрольную\") выборку\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось ли, что смещение практически нулевое, как мы и ожидали? Или хотя бы близко к нулю? Как вы думаете, почему так происходит? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Эксперимент.__\n",
    "\n",
    "Итак, теперь мы можем попробовать выяснить ответ на наш вопрос: как меняется уровень коррелированности деревьев при увеличении глубины. Рассмотрите пары одинаковых деревьев глубины [1, 2, 3, 4, 5], обученных по разным подвыборкам, и оцените их коррелированность. Чтобы результат был менее шумным, можно для каждого значения глубины обучать несколько пар деревьев и усреднять значение корреляции. Напечатайте или постройте график корреляция - глубина дерева. Получился ли он убывающим? Дошел ли уровень корреляции до нуля?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Еще один эксперимент.__\n",
    "\n",
    "В лекции говорилось, что чем меньше корреляция, тем лучше должно быть качество композиции. График корреляции мы построили, теперь надо сравнить его с графиком качества. \n",
    "\n",
    "Используя всю перемешанную выборку boston, постройте графиков MSE - глубина дерева на кросс-валидации с треми блоками. Реализация кросс-валдиации - cross_val_score или GridSearchCV на ваше усмотрение. Вроде как в данной ситуации проще использовать cross_val_score и цикл по глубине дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score # использовать scoring=\"neg_mean_squared_error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у вас еще осталось время, то теперь мега-челендж: оформите свой код так, чтобы в нем почти не было копипаста.\n",
    "\n",
    "Если у вас все еще осталось время (и желание), то можете теперь аналогично поэкспериментировать с параметром max_features, рассмотрев все возможные его значения для задачи Бостон (от 1 до 13)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
